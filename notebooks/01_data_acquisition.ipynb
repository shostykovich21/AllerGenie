{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959d742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 01 â€“ Data acquisition ðŸ“¦  (v2)\n",
    "#\n",
    "# 0. Imports & paths\n",
    "import os, json, zipfile, shutil, subprocess, time, re, requests, itertools\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "RAW   = Path(\"/mnt/ssd1/saumia/data/raw\");   \n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "IMG   = Path(\"/mnt/ssd1/saumia/data/images\"); \n",
    "IMG.mkdir(parents=True,  exist_ok=True)\n",
    "TEXT  = Path(\"/mnt/ssd1/saumia/data/text\");  \n",
    "TEXT.mkdir(parents=True,  exist_ok=True)\n",
    "MEDS  = Path(\"/mnt/ssd1/saumia/data/meds\");  \n",
    "MEDS.mkdir(parents=True,  exist_ok=True)\n",
    "\n",
    "IMG_EXT = {\".png\", \".jpg\", \".jpeg\", \".bmp\"}\n",
    "\n",
    "def unzip_here(z: Path):\n",
    "    with zipfile.ZipFile(z) as zf: zf.extractall(RAW)\n",
    "    z.unlink()\n",
    "\n",
    "import subprocess, zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def kaggle_dl(slug: str):\n",
    "    owner, name = slug.split(\"/\")\n",
    "    zip_name = f\"{name}.zip\"\n",
    "    target   = RAW / zip_name\n",
    "\n",
    "    print(f\"â—¼ Kaggle {slug}\")\n",
    "    subprocess.run(\n",
    "        [\"kaggle\", \"datasets\", \"download\", \"-d\", slug, \"-p\", str(RAW), \"--force\"],\n",
    "        check=True\n",
    "    )\n",
    "\n",
    "    # Only unzip if a proper ZIP was downloaded\n",
    "    if target.exists():\n",
    "        try:\n",
    "            with zipfile.ZipFile(target, \"r\") as zf:\n",
    "                print(f\"  â†³ Extracting {zip_name} â€¦\")\n",
    "                zf.extractall(RAW)\n",
    "        except zipfile.BadZipFile:\n",
    "            print(f\"âš  Warning: {zip_name} is not a valid ZIP, skipping unzip\")\n",
    "        finally:\n",
    "            target.unlink()\n",
    "    else:\n",
    "        print(f\"  â†³ No {zip_name} found; assuming direct file download\")\n",
    "\n",
    "\n",
    "def move_imgs(folder: Path):\n",
    "    for p in folder.rglob(\"*\"):\n",
    "        if p.suffix.lower() in IMG_EXT:\n",
    "            cls = p.parent.name.replace(\" \", \"_\").lower()\n",
    "            dst = IMG/cls; \n",
    "            subprocess.run([\"sudo\", \"mkdir\", \"-p\", str(dst)], check=True)\n",
    "            subprocess.run([\"sudo\", \"mv\", str(p), str(dst/p.name)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a352de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â—¼ Kaggle shubhamgoel27/dermnet\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
      "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
      "Downloading dermnet.zip to ../mnt/ssd1/saumia/data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.72G/1.72G [00:01<00:00, 992MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  â†³ Extracting dermnet.zip â€¦\n",
      "â—¼ Kaggle ismailpromus/skin-diseases-image-dataset\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/ismailpromus/skin-diseases-image-dataset\n",
      "License(s): copyright-authors\n",
      "Downloading skin-diseases-image-dataset.zip to ../mnt/ssd1/saumia/data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.19G/5.19G [00:05<00:00, 940MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  â†³ Extracting skin-diseases-image-dataset.zip â€¦\n",
      "â—¼ Kaggle subirbiswas19/skin-disease-dataset\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/subirbiswas19/skin-disease-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading skin-disease-dataset.zip to ../mnt/ssd1/saumia/data/raw\n",
      "\n",
      "  â†³ Extracting skin-disease-dataset.zip â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.3M/17.3M [00:00<00:00, 848MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â—¼ Kaggle henriqueolivoantonio/allergy-degrees\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/henriqueolivoantonio/allergy-degrees\n",
      "License(s): ODbL-1.0\n",
      "Downloading allergy-degrees.zip to ../mnt/ssd1/saumia/data/raw\n",
      "\n",
      "  â†³ Extracting allergy-degrees.zip â€¦\n",
      "â—¼ Kaggle boltcutters/food-allergens-and-allergies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6M/13.6M [00:00<00:00, 820MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/boltcutters/food-allergens-and-allergies\n",
      "License(s): copyright-authors\n",
      "Downloading food-allergens-and-allergies.zip to ../mnt/ssd1/saumia/data/raw\n",
      "\n",
      "  â†³ Extracting food-allergens-and-allergies.zip â€¦\n",
      "â—¼ Kaggle niyarrbarman/symptom2disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.17k/2.17k [00:00<00:00, 2.32MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/niyarrbarman/symptom2disease\n",
      "License(s): CC0-1.0\n",
      "Downloading symptom2disease.zip to ../mnt/ssd1/saumia/data/raw\n",
      "\n",
      "  â†³ Extracting symptom2disease.zip â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43.6k/43.6k [00:00<00:00, 103MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 1 â€“ Kaggle datasets (images + tables)\n",
    "KAGGLE_LIST = [\n",
    "    \"shubhamgoel27/dermnet\",\n",
    "    \"ismailpromus/skin-diseases-image-dataset\",\n",
    "    \"subirbiswas19/skin-disease-dataset\",\n",
    "    \"henriqueolivoantonio/allergy-degrees\",\n",
    "    \"boltcutters/food-allergens-and-allergies\",\n",
    "    \"niyarrbarman/symptom2disease\",\n",
    "\n",
    "]\n",
    "for slug in KAGGLE_LIST: kaggle_dl(slug)\n",
    "\n",
    "# bucket images â†’ images/\n",
    "for src in [\n",
    "    RAW/\"dermnet\",                       # shubhamgoel27\n",
    "    RAW/\"Skin diseases\",                 # ismailpromus\n",
    "    RAW/\"skin disease dataset\"           # subirbiswas\n",
    "]:\n",
    "    if src.exists(): move_imgs(src)\n",
    "\n",
    "# copy any CSV/JSON tables â†’ text/\n",
    "for p in RAW.rglob(\"*\"):\n",
    "    if p.suffix.lower() in {\".csv\", \".json\"}:\n",
    "        subprocess.run([\"sudo\", \"cp\", str(p), str(TEXT/p.name)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fdd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âžœ Kaggle niyarrbarman/symptom2disease\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/saumia/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/niyarrbarman/symptom2disease\n",
      "License(s): CC0-1.0\n",
      "Downloading symptom2disease.zip to /mnt/ssd1/saumia/data/raw\n",
      "\n",
      "âœ… Symptom2Disease.csv copied to data/text/symptom2disease.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43.6k/43.6k [00:00<00:00, 99.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Fetch Symptom2Disease from Kaggle\n",
    "\n",
    "# %%\n",
    "import subprocess, zipfile, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "RAW = Path(\"/mnt/ssd1/saumia/data/raw\")\n",
    "TEXT = Path(\"/mnt/ssd1/saumia/data/text\"); TEXT.mkdir(exist_ok=True)\n",
    "\n",
    "# Dataset slug\n",
    "slug = \"niyarrbarman/symptom2disease\"\n",
    "print(f\"âžœ Kaggle {slug}\")\n",
    "\n",
    "# Download & unzip\n",
    "subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"download\", \"-d\", slug, \"-p\", str(RAW)],\n",
    "    check=True\n",
    ")\n",
    "\n",
    "# Extract all zip files matching pattern\n",
    "for z in RAW.glob(\"symptom2disease*.zip\"):\n",
    "    with zipfile.ZipFile(z) as zf:\n",
    "        zf.extractall(RAW)\n",
    "    z.unlink()\n",
    "\n",
    "# Locate CSV file (case-insensitive pattern match)\n",
    "csv_candidates = list(RAW.glob(\"*ymptom2*isease*.csv\"))\n",
    "if not csv_candidates:\n",
    "    raise FileNotFoundError(\"âŒ No Symptom2Disease CSV file found in RAW folder.\")\n",
    "\n",
    "csv = csv_candidates[0]\n",
    "\n",
    "# Safely copy to text folder, handling overwrite/casing conflict\n",
    "target = TEXT / \"symptom2disease.csv\"\n",
    "if target.exists():\n",
    "    target.unlink()  # prevent overwrite issue on case-insensitive FS\n",
    "    \n",
    "subprocess.run([\"sudo\", \"cp\", str(csv), str(target)], check=True)\n",
    "print(f\"âœ… {csv.name} copied to data/text/symptom2disease.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7597c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  Skip ISIC (set ISIC_USERNAME/PASSWORD env-vars to enable)\n"
     ]
    }
   ],
   "source": [
    "# 4 â€“ ISIC Archive (skin-lesion images)\n",
    "user = os.getenv(\"ISIC_USERNAME\"); pwd = os.getenv(\"ISIC_PASSWORD\")\n",
    "if user and pwd:\n",
    "    print(\"â—¼ ISIC Archive loginâ€¦\")\n",
    "    sess = requests.Session()\n",
    "    r = sess.post(\"https://isic-archive.com/api/v2/login\", json={\n",
    "        \"username\": user, \"password\": pwd})\n",
    "    r.raise_for_status()\n",
    "    token = r.json()[\"authToken\"][\"token\"]\n",
    "\n",
    "    HDR = {\"Authorization\": f\"token {token}\"}\n",
    "    #  fetch 1000 public images with metadata â€œbenignâ€/â€œmalignantâ€\n",
    "    params = {\"limit\": 1000, \"offset\": 0, \"sort\": \"name\", \"sortdir\": 1}\n",
    "    items = sess.get(\"https://isic-archive.com/api/v2/image\", headers=HDR,\n",
    "                     params=params).json()\n",
    "    print(f\"  â†³ downloading {len(items)} thumbnails â€¦\")\n",
    "    for it in tqdm(items):\n",
    "        url = it['_links']['thumbnail']  # 224Ã—224 JPEG\n",
    "        img = sess.get(url, headers=HDR).content\n",
    "        cls = \"isic_\" + it['meta']['clinical']['benign_malignant']\n",
    "        (IMG/cls).mkdir(exist_ok=True)\n",
    "        with open(IMG/cls/f\"{it['_id']}.jpg\", \"wb\") as f: f.write(img)\n",
    "else:\n",
    "    print(\"âš  Skip ISIC (set ISIC_USERNAME/PASSWORD env-vars to enable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6218697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Scanning mendeley_images ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Scanning mendeley_images1 ...\n",
      "ðŸ” Scanning mendeley_images2 ...\n",
      "âœ… Done: All Mendeley images copied to data/images/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil, hashlib, cv2\n",
    "\n",
    "RAW      = Path(\"/mnt/ssd1/saumia/data/raw\")\n",
    "IMG_DIR  = Path(\"/mnt/ssd1/saumia/data/images\")\n",
    "IMG_EXT  = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "seen     = set()\n",
    "\n",
    "# All 3 folders you unzipped\n",
    "parts = [\n",
    "    RAW / \"mendeley_images\",\n",
    "    RAW / \"mendeley_images1\",\n",
    "    RAW / \"mendeley_images2\",\n",
    "]\n",
    "\n",
    "for part in parts:\n",
    "    print(f\"ðŸ” Scanning {part.name} ...\")\n",
    "    for p in part.rglob(\"*\"):\n",
    "        if p.suffix.lower() not in IMG_EXT:\n",
    "            continue\n",
    "        img = cv2.imread(str(p))\n",
    "        if img is None or min(img.shape[:2]) < 50:\n",
    "            continue\n",
    "        h = hashlib.sha1(img).hexdigest()\n",
    "        if h in seen:\n",
    "            continue\n",
    "        seen.add(h)\n",
    "        cls = p.parent.name.replace(\" \", \"_\").lower()\n",
    "        dst = IMG_DIR / cls\n",
    "        subprocess.run([\"sudo\", \"mkdir\", \"-p\", str(dst)], check=True)\n",
    "        subprocess.run([\"sudo\", \"cp\", str(p), str(dst / p.name)], check=True)\n",
    "\n",
    "print(\"âœ… Done: All Mendeley images copied to data/images/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 â€“ openFDA drug-label dumps (medication look-ups)\n",
    "FDA = \"https://api.fda.gov/drug/label.json\"\n",
    "PAGES = 5\n",
    "for skip in range(0, PAGES*1000, 1000):\n",
    "    fname = MEDS/f\"drug_label_{skip//1000:02d}.json\"\n",
    "    if fname.exists(): continue\n",
    "    print(f\"â—¼ openFDA page {skip//1000}\")\n",
    "    r = requests.get(FDA, params={\"limit\":1000, \"skip\":skip}, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    subprocess.run([\"sudo\", \"tee\", str(fname)], input=r.text.encode(\"utf-8\"), check=True)\n",
    "    time.sleep(.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170061a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Loading Symptom2Disease.csv\n",
      "   Wrote symptom2disease.csv (1,200 rows)\n",
      "â†’ Loading FoodData.csv\n",
      "   Wrote fooddata.csv (184 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "for f in RAW.iterdir():\n",
    "    ext = f.suffix.lower()\n",
    "    if ext in (\".xlsx\", \".xls\", \".xlsm\", \".csv\"):\n",
    "        print(f\"â†’ Loading {f.name}\")\n",
    "        if ext in (\".xlsx\", \".xls\", \".xlsm\"):\n",
    "            df = pd.read_excel(f, engine=\"openpyxl\")\n",
    "        else:\n",
    "            df = pd.read_csv(f)\n",
    "        df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "        df = df.dropna(how=\"all\")\n",
    "        out = TEXT / f\"{f.stem.lower().replace(' ', '_')}.csv\"\n",
    "        subprocess.run([\"sudo\", \"cp\", str(f), str(out)], check=True)\n",
    "        print(f\"   Wrote {out.name} ({len(df):,} rows)\")\n",
    "\n",
    "    elif ext == \".json\":\n",
    "        dest = TEXT / f.name\n",
    "        shutil.copy2(f, dest)\n",
    "        print(f\"   Copied {f.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2f429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
